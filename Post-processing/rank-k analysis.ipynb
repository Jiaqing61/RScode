{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T16:42:25.809656Z",
     "start_time": "2025-06-08T16:42:14.016085Z"
    }
   },
   "source": [
    "from recbole.quick_start import load_data_and_model\n",
    "from recbole.utils.case_study import full_sort_topk\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1. 加载模型和数据\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(\n",
    "    model_file='../checkpoint_saved/ml-1m/BPR-Jun-08-2025_14-26-19.pth'\n",
    ")\n",
    "\n",
    "# Step 1: Get all internal user IDs\n",
    "all_uids = list(range(dataset.user_num))\n",
    "\n",
    "# Step 2: Filter out users who have no interactions in the test set\n",
    "valid_uids = [uid for uid in tqdm(all_uids) if test_data.uid2history_item[uid] is not None]\n",
    "\n",
    "# Step 3: Convert to Series\n",
    "import numpy as np\n",
    "uid_series = np.array(valid_uids)\n",
    "\n",
    "# Step 4: Run full_sort_topk\n",
    "topk_scores, topk_index = full_sort_topk(uid_series, model, test_data, k=10, device=config['device'])\n",
    "\n",
    "# Step 5: Convert internal item IDs to external tokens\n",
    "external_item_lists = [dataset.id2token(dataset.iid_field, row.cpu().tolist()) for row in topk_index]\n",
    "external_user_list = [dataset.id2token(dataset.uid_field, [uid])[0] for uid in uid_series]\n",
    "\n",
    "# Step 6: Save as DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'user_id': external_user_list,\n",
    "    'topk_items': [','.join(items) for items in external_item_lists]\n",
    "})\n",
    "display(df.head())\n",
    "df.to_csv('outputs/all_user_top10.csv', index=False)\n",
    "print(\"save all_user_top10 successfully\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08 Jun 18:42    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 42\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = datasets/ml-1m\n",
      "checkpoint_dir = ../checkpoint_saved/ml-1m/\n",
      "show_progress = True\n",
      "save_dataset = True\n",
      "dataset_save_path = None\n",
      "save_dataloaders = True\n",
      "dataloaders_save_path = None\n",
      "log_wandb = True\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 100\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.0005\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'Precision', 'Hit', 'NDCG', 'ItemCoverage', 'AveragePopularity', 'GiniIndex', 'ShannonEntropy', 'TailPercentage']\n",
      "topk = [10]\n",
      "valid_metric = NDCG@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 3}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = jiaqing61-tud\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "workers = 2\n",
      "encoding = utf-8\n",
      "output_path = ../outputs/results/ml-1m/\n",
      "wandb_path = outputs/\n",
      "wandb_run_id = None\n",
      "wandb_run_name = None\n",
      "date = None\n",
      "timestamp = None\n",
      "log_root = ../outputs/logs/\n",
      "skip_test = False\n",
      "tail_ratio = 0.2\n",
      "reg_weight = 0.0003\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "/Users/huangjiaqing/Desktop/Recommender Systems/RScode/.venv/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/Users/huangjiaqing/Desktop/Recommender Systems/RScode/.venv/lib/python3.10/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "08 Jun 18:42    INFO  Saving filtered dataset into [../checkpoint_saved/ml-1m/ml-1m-Dataset.pth]\n",
      "08 Jun 18:42    INFO  ml-1m\n",
      "The number of users: 6041\n",
      "Average actions of users: 165.5975165562914\n",
      "The number of items: 3707\n",
      "Average actions of items: 269.88909875876953\n",
      "The number of inters: 1000209\n",
      "The sparsity of the dataset: 95.53358229599758%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp', 'label']\n",
      "08 Jun 18:42    INFO  Saving split dataloaders into: [../checkpoint_saved/ml-1m/ml-1m-for-BPR-dataloader.pth]\n",
      "08 Jun 18:42    INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "08 Jun 18:42    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "100%|██████████| 6041/6041 [00:00<00:00, 2156774.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  user_id                                        topk_items\n",
       "0       1            595,34,364,919,1,588,2081,3114,318,594\n",
       "1       2      2028,1183,590,3418,527,1610,318,349,608,1393\n",
       "2       3     1210,260,1196,1198,1270,480,356,1580,2716,110\n",
       "3       4     1196,260,1210,1198,858,1214,1240,480,541,2028\n",
       "4       5  2997,2692,2908,2858,2333,2599,2959,223,2395,2318"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>topk_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>595,34,364,919,1,588,2081,3114,318,594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2028,1183,590,3418,527,1610,318,349,608,1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1210,260,1196,1198,1270,480,356,1580,2716,110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1196,260,1210,1198,858,1214,1240,480,541,2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2997,2692,2908,2858,2333,2599,2959,223,2395,2318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save all_user_top10 successfully\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T16:51:34.909088Z",
     "start_time": "2025-06-08T16:51:34.540090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: 加载推荐结果 & 用户性别\n",
    "topk_df = pd.read_csv('outputs/all_user_top10.csv')\n",
    "user_df = pd.read_csv('../datasets/atomic_datasets/ml-1m/ml-1m.user', sep='\\t')\n",
    "user2gender = dict(zip(user_df['user_id:token'], user_df['gender:token']))\n",
    "\n",
    "# Step 2: 加载测试集 ground truth（正反馈）\n",
    "test_df = pd.read_csv('../datasets/split_datasets/ml-1m/ml-1m.test.inter', sep='\\t')\n",
    "test_df = test_df[test_df['label:float'] == 1.0]\n",
    "user2ground_truth = test_df.groupby('user_id:token')['item_id:token'].agg(set).to_dict()\n",
    "\n",
    "# Step 3: NDCG@10 计算函数\n",
    "def ndcg_at_k(preds, true_items, k=10):\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(preds[:k]):\n",
    "        if item in true_items:\n",
    "            dcg += 1.0 / np.log2(i + 2)\n",
    "    ideal_len = min(len(true_items), k)\n",
    "    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_len))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# Step 4: 分组统计\n",
    "ndcg_male, ndcg_female, ndcg_all = [], [], []\n",
    "\n",
    "for _, row in topk_df.iterrows():\n",
    "    uid = row['user_id']\n",
    "    pred_items = eval(row['topk_items']) if isinstance(row['topk_items'], str) else row['topk_items']\n",
    "    true_items = user2ground_truth.get(uid, set())\n",
    "    gender = user2gender.get(uid, None)\n",
    "\n",
    "    if gender not in ('M', 'F') or not true_items:\n",
    "        continue\n",
    "\n",
    "    ndcg = ndcg_at_k(pred_items, true_items, k=10)\n",
    "    if gender == 'M':\n",
    "        ndcg_male.append(ndcg)\n",
    "        ndcg_all.append(ndcg)\n",
    "    else:\n",
    "        ndcg_female.append(ndcg)\n",
    "        ndcg_all.append(ndcg)\n",
    "\n",
    "# Step 5: 输出\n",
    "print(f'NDCG@10 (All):    {np.mean(ndcg_all):.4f} over {len(ndcg_all)} users')\n",
    "print(f'NDCG@10 (Male):   {np.mean(ndcg_male):.4f} over {len(ndcg_male)} users')\n",
    "print(f'NDCG@10 (Female): {np.mean(ndcg_female):.4f} over {len(ndcg_female)} users')"
   ],
   "id": "141e49f35fb7164b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10 (All):    0.0756 over 6012 users\n",
      "NDCG@10 (Male):   0.0770 over 4312 users\n",
      "NDCG@10 (Female): 0.0721 over 1700 users\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b25dfe1ba1654d74"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
